{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-l', '--lr'], dest='lr', nargs=None, const=None, default=0.001, type=<class 'float'>, choices=None, required=False, help=None, metavar=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gurobipy as gp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from helper import getCandidates\n",
    "from model import var_sorter\n",
    "\n",
    "\n",
    "#torch devices\n",
    "# device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device=torch.device(\"mps\")\n",
    "cpu_dev=torch.device('cpu')\n",
    "\n",
    "\n",
    "# adding args\n",
    "OUTPUT=True\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-p', '--problem', type=str,default='ip')\n",
    "parser.add_argument('-n', '--nnode', type=int,default=5)\n",
    "parser.add_argument('-s', '--nstep', type=int,default=100)\n",
    "parser.add_argument('-l', '--lr', type=float,default=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = parser.parse_args()\n",
    "args = parser.parse_args(['-p', 'ip', '-n', '5', '-s', '100', '-l', '0.001'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up torch model\n",
    "m=var_sorter(6,2,[64,128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read MPS format model from file /Users/aaron/Downloads/benchmark/50v-10.mps.gz\n",
      "Reading time = 0.03 seconds\n",
      "50v-10: 233 rows, 2013 columns, 2745 nonzeros\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gurobi.Model MIP instance 50v-10: 233 constrs, 2013 vars, Parameter changes: Username=(user-defined)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load instance info\n",
    "ins_dir=f'/Users/aaron/Downloads/benchmark/50v-10.mps.gz'\n",
    "# mscp=gp.Model()\n",
    "mscp1 = gp.read(ins_dir)\n",
    "mscp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nCons: 233\n"
     ]
    }
   ],
   "source": [
    "#construct CGLP\n",
    "mcglp=gp.Model()\n",
    "#mcglp.enableReoptimization()\n",
    "cglp_var=[]\n",
    "cglp_mult=[]\n",
    "cglp_coeff=[]\n",
    "\n",
    "#get variables global\n",
    "mvars=mscp1.getVars()   #get all variables\n",
    "vmap={}                 #var name to var\n",
    "v_indx_map={}           #var name to index\n",
    "v_list=[]\n",
    "cglp_var.append(mcglp.addVar(vtype=gp.GRB.CONTINUOUS,name=f'pi_0',obj=-1.0))\n",
    "#cglp_coeff.append(-1.0)\n",
    "#set cut coefficients [pi_0,pi_1,...,pi_n]\n",
    "vct=0\n",
    "for v in mvars:\n",
    "    vnm=v.getAttr('VarName')\n",
    "    vmap[vnm]=v\n",
    "    v_indx_map[vnm]=vct\n",
    "    v_list.append(v)\n",
    "    vct+=1\n",
    "    #CGLP var\n",
    "    tmp_var=mcglp.addVar(vtype=gp.GRB.CONTINUOUS,name=f'pi_{vnm}',obj=0.0)\n",
    "    cglp_var.append(tmp_var)\n",
    "    #cglp_coeff.append(0.0)\n",
    "mcglp.update()\n",
    "# current_nrow=mscp.getNConss()\n",
    "current_nrow=mscp1.getAttr('NumConstrs')\n",
    "print(f'nCons: {current_nrow}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training=True\n",
    "\n",
    "last_obj=-1e+20\n",
    "node_limit=0\n",
    "\n",
    "step=0\n",
    "init_obj=None\n",
    "\n",
    "optimizer=torch.optim.Adam(m.parameters(),lr=args.lr)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "# for step in range(args.nstep):\n",
    "    # node_limit+=1\n",
    "    # mscp.setParam('NodeLimit',1)\n",
    "    #mscp.writeProblem('verifyMSCP.lp')\n",
    "\n",
    "    #start training cycle\n",
    "\n",
    "labels=None\n",
    "logits=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback function has two arguments: model and where, `where` indicates the position of the solving process\n",
    "def cbk(mscp, where): \n",
    "    global step\n",
    "    global last_obj\n",
    "    global init_obj\n",
    "    global optimizer\n",
    "    global loss_func\n",
    "    global training\n",
    "    global labels\n",
    "    global logits\n",
    "    if not where == gp.GRB.Callback.MIPNODE: # check wether the callback function in at a node of BB tree\n",
    "        return\n",
    "    # step=mscp.cbGet(gp.GRB.Callback.MIPNODE_NODCNT)\n",
    "    step+=1\n",
    "    print(f'calling callback step{step}')\n",
    "    current_nrow=mscp.getAttr('NumConstrs')\n",
    "    \n",
    "    #get A matrix\n",
    "    Ak=[] #sparse matrix, indexed by 0..m-1, inside stored as tuple (0..n-1,val)\n",
    "    rhs=[0]*current_nrow\n",
    "    for i in range(len(vmap)):\n",
    "        Ak.append([])\n",
    "    for cidx,c in enumerate(mscp.getConstrs()):\n",
    "        row=mscp.getRow(c)\n",
    "        row_nv=row.size()\n",
    "        rhs[cidx]=c.RHS\n",
    "        for col_indx in range(row_nv):\n",
    "            vnm2=row.getVar(col_indx).VarName\n",
    "            vidx=v_indx_map[vnm2]\n",
    "            Ak[vidx].append((cidx,row.getCoeff(col_indx)))\n",
    "            #print(vnm,cidx,vidx,coeffs[vnm])  \n",
    "    #quit()\n",
    "\n",
    "    #get current node embedding\n",
    "    cand, col_feat, row_feat, A, col_index_map, lp_sol_map = getCandidates(mscp,vmap)\n",
    "    lpobj=mscp.cbGet(gp.GRB.Callback.MIPNODE_OBJBND)\n",
    "    # print(col_feat)\n",
    "    # quit()\n",
    "    #update records\n",
    "    improvement=0.0\n",
    "    if last_obj<lpobj:\n",
    "        improvement=lpobj-last_obj\n",
    "\n",
    "    #TODO::add training\n",
    "    if training and init_obj is not None:\n",
    "        label=torch.zeros(logits.shape)\n",
    "        label[labels]=1.0*1000.0*(improvement/init_obj)\n",
    "        # print(label.shape,labels,label)\n",
    "        # quit()\n",
    "        loss = loss_func(logits,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    elif init_obj is None:\n",
    "        init_obj=lpobj\n",
    "    # if training:\n",
    "\n",
    "    # if step==0:\n",
    "    #     last_obj=lpobj\n",
    "    #     print(f'Initial Bound/LP Obj: {last_obj}')\n",
    "    #     continue\n",
    "    \n",
    "    #predict\n",
    "    if training:\n",
    "        optimizer.zero_grad()\n",
    "    print('----------Predicting.....',end='')\n",
    "    logits=m(A,col_feat,row_feat)       # logits is a tensor, predicted is a list\n",
    "    print('Done---------')\n",
    "    cand_indx=[col_index_map[x] for x in cand]\n",
    "\n",
    "    logits_map={}\n",
    "    for idx,vname in enumerate(cand):\n",
    "        logits_map[vname]=[logits[cand_indx[idx]].item(),idx]\n",
    "        \n",
    "    logits_map=sorted(logits_map.items(),key=lambda x:x[1][0],reverse=True)[:args.nnode]\n",
    "    \n",
    "    #for debugging\n",
    "    predicted_=set()\n",
    "    labels=[]\n",
    "    if OUTPUT:\n",
    "        print(f'  ::::::  Step: {step}, #rows:{current_nrow}\\n        --- LP Obj  : {lpobj}\\n        --- last Obj: {last_obj}\\n        *** imp: {improvement}')\n",
    "        print(f'---------------------------------------')\n",
    "        print(f'|  #  |  VName  |  logits  |  LP Sol  |')\n",
    "        print(f'---------------------------------------')\n",
    "        # '{:10s} {:3d}  {:7.2f}'.format('xxx', 123, 98)\n",
    "        for idx,ele in enumerate(logits_map):\n",
    "            print('| '+'{:4d}'.format(idx)+'|  '+'{:7s}'.format(ele[0])+'| '+'{:8.4f}'.format(ele[1][0])+' | '+'{:8.4f}'.format(lp_sol_map[ele[0]])+' |')\n",
    "            predicted_.add(ele[0])\n",
    "            labels.append(ele[1][1])\n",
    "        print(f'---------------------------------------')\n",
    "        input('Press key to continue')\n",
    "    \n",
    "    last_obj=lpobj\n",
    "\n",
    "\n",
    "    #Update CGLP\n",
    "    for cglp_idx in range(1,len(cglp_var)):\n",
    "        v=cglp_var[cglp_idx]\n",
    "        v.setAttr('Obj',lp_sol_map[v.VarName.replace('pi_','')])\n",
    "    # add constraints\n",
    "    # 1. pi constraints (m)\n",
    "    tmp_lambda=[]\n",
    "    tmp_mu=[]\n",
    "    tmp_v=[]\n",
    "    for i in range(0,len(cglp_var)-1):\n",
    "        tmp_var=mcglp.addVar(vtype=gp.GRB.CONTINUOUS,name=f'mu_{step}_{i}',obj=0.0)\n",
    "        tmp_mu.append(tmp_var)\n",
    "        tmp_var=mcglp.addVar(vtype=gp.GRB.CONTINUOUS,name=f'v_{step}_{i}',obj=0.0)\n",
    "        tmp_v.append(tmp_var)\n",
    "    for i in range(current_nrow):\n",
    "        tmp_var=mcglp.addVar(vtype=gp.GRB.CONTINUOUS,name=f'lambda_{step}_{i}',obj=0.0)\n",
    "        tmp_lambda.append(tmp_var)\n",
    "    for i in range(1,len(cglp_var)):\n",
    "        tmp_coeff=[]\n",
    "        #deal with pi var, coeff should be -1\n",
    "        tmp_coeff.append((cglp_var[i],-1))\n",
    "\n",
    "        #deal with mu/v\n",
    "        tmp_bound=v_list[i-1].LB\n",
    "        if tmp_bound>-1e+20:\n",
    "            tmp_coeff.append((tmp_mu[i-1],1)) \n",
    "        tmp_bound=v_list[i-1].UB\n",
    "        if tmp_bound<1e+20:\n",
    "            tmp_coeff.append((tmp_v[i-1],-1)) \n",
    "        #deal with lambda \n",
    "        #  first with A, then with cuts\n",
    "        #   basically for pi_m, we need to compute A[:,i-1]^\\top \\lambda\n",
    "        for nindx,ent in enumerate(Ak[i-1]):\n",
    "            tmp_coeff.append((tmp_lambda[ent[0]],ent[-1])) # append([lambda_n, A_{n,i-1}])\n",
    "        mcglp.addConstr(gp.quicksum(k[0]*k[1] for k in tmp_coeff) == 0, f'cons_{step}_pi_{i}')\n",
    "    tmp_coeff=[(cglp_var[0],-1)]\n",
    "    for i in range(current_nrow):\n",
    "        tmp_coeff.append((tmp_lambda[i],rhs[i]))\n",
    "    for i in range(1,len(cglp_var)):\n",
    "        vnm=v_list[i-1].VarName\n",
    "        tmp_bound=round(mscp.cbGetNodeRel(v_list[i-1]))\n",
    "\n",
    "        if vnm not in predicted_:\n",
    "            tmp_bound=v_list[i-1].LB\n",
    "        if tmp_bound<=-1e+20:\n",
    "            tmp_bound=0\n",
    "        else:\n",
    "            tmp_coeff.append((tmp_mu[i-1],tmp_bound)) \n",
    "        if vnm not in predicted_:\n",
    "            tmp_bound=v_list[i-1].UB\n",
    "        if tmp_bound>=1e+20:\n",
    "            tmp_bound=0\n",
    "        else:\n",
    "            tmp_coeff.append((tmp_v[i-1],tmp_bound)) \n",
    "    mcglp.addConstr(gp.quicksum(k[0]*k[1] for k in tmp_coeff) >= 0, f'cons_{step}_pi0')\n",
    "    mcglp.addConstr(gp.quicksum(tmp_lambda+tmp_mu+tmp_v) == 1, f'norm_{step}')\n",
    "    \n",
    "        \n",
    "    mcglp.write(f'verify{step}.lp')\n",
    "    \n",
    "    \n",
    "    mcglp.update()\n",
    "    mcglp.optimize()    \n",
    "    vss=mcglp.getVars()\n",
    "    #for v in vss:\n",
    "    #    print(v.name,mcglp.getVal(v))\n",
    "        \n",
    "        \n",
    "    local_vmap={}\n",
    "    for v in mscp.getVars():\n",
    "        local_vmap[v.VarName]=v\n",
    "    \n",
    "    \n",
    "\n",
    "    newCut=gp.LinExpr(cglp_var[0].X) # \\times -1?\n",
    "    for v in cglp_var[1:]:\n",
    "        ori_name=v.VarName[3:]       # pi_xxx\n",
    "        ori_var=local_vmap[ori_name] # x\n",
    "        # print(v,ori_name,v.X,ori_var)\n",
    "        newCut+=ori_var*v.X\n",
    "    mscp.cbCut(newCut>=0.0)\n",
    "    print(f'Finished step{step}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "- Where is the simplified cutting plane tree? We need to have a constraint (2), i.e., `mcglp.addConstr(gp.quicksum(k[0]*k[1] for k in tmp_coeff) == 0, f'cons_{step}_pi_{i}')` for each leaf node (even for the new tree).\n",
    "- `newCut`, should be `-1 * cglp_var[0].X + pi * x` ?\n",
    "- functions in `helper.py`\n",
    "- Let us talk about the NN structure/ RL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 11.0.0 build v11.0.0rc2 (mac64[arm] - Darwin 23.1.0 23B2091)\n",
      "\n",
      "CPU model: Apple M3 Max\n",
      "Thread count: 16 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Optimize a model with 233 rows, 2013 columns and 2745 nonzeros\n",
      "Model fingerprint: 0x0fae2ab0\n",
      "Variable types: 366 continuous, 1647 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+02]\n",
      "  Objective range  [2e+00, 7e+02]\n",
      "  Bounds range     [1e+00, 2e+02]\n",
      "  RHS range        [1e+01, 1e+03]\n",
      "Found heuristic solution: objective 24351.509936\n",
      "Presolve time: 0.00s\n",
      "Presolved: 233 rows, 2013 columns, 2745 nonzeros\n",
      "Variable types: 366 continuous, 1647 integer (1464 binary)\n",
      "Found heuristic solution: objective 20200.229981\n",
      "\n",
      "Root relaxation: objective 2.879066e+03, 492 iterations, 0.00 seconds (0.01 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2879.06569    0   29 20200.2300 2879.06569  85.7%     -    0s\n",
      "H    0     0                    5473.0600023 2879.06569  47.4%     -    0s\n",
      "H    0     0                    4175.5599932 2879.06569  31.0%     -    0s\n",
      "H    0     0                    3926.0599857 2879.06569  26.7%     -    0s\n",
      "H    0     0                    3785.8399915 2879.06569  24.0%     -    0s\n",
      "H    0     0                    3539.6699854 2879.06569  18.7%     -    0s\n",
      "H    0     0                    3483.7599893 2879.06569  17.4%     -    0s\n",
      "calling callback step1\n",
      "total vars:2013, frac/cand vars:29\n",
      "----------Predicting.....Done---------\n",
      "  ::::::  Step: 1, #rows:233\n",
      "        --- LP Obj  : 2897.9740200492515\n",
      "        --- last Obj: -1e+20\n",
      "        *** imp: 1e+20\n",
      "---------------------------------------\n",
      "|  #  |  VName  |  logits  |  LP Sol  |\n",
      "---------------------------------------\n",
      "|    0|  x1959  |   0.1754 |   0.2222 |\n",
      "|    1|  x375   |   0.1632 |   0.0648 |\n",
      "|    2|  x1320  |  -0.0002 |   0.4120 |\n",
      "|    3|  x1284  |  -0.0002 |   0.4444 |\n",
      "|    4|  x1932  |  -0.0004 |   0.3704 |\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mscp1.optimize(cbk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
